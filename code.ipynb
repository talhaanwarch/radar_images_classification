{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7549de2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pytorch_lightning import seed_everything, LightningModule, Trainer\n",
    "from sklearn.utils import class_weight\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from pytorch_lightning.callbacks import EarlyStopping,ModelCheckpoint,LearningRateMonitor\n",
    "from torch.optim.lr_scheduler import CyclicLR, ReduceLROnPlateau,CosineAnnealingWarmRestarts,OneCycleLR,CosineAnnealingLR\n",
    "import torchvision\n",
    "from sklearn.metrics import classification_report,f1_score,accuracy_score\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset,random_split\n",
    "import timm\n",
    "import torchmetrics\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb43ad1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size=128\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "aug= A.Compose([\n",
    "            A.Resize(img_size,img_size),\n",
    "            #A.RandomCrop(img_size,img_size),\n",
    "            A.HorizontalFlip(0.5),\n",
    "            A.VerticalFlip(),\n",
    "            A.RandomRotate90(),\n",
    "#             A.ShiftScaleRotate(rotate_limit=3),\n",
    "            #A.CoarseDropout(8,64,64),\n",
    "            A.Normalize(),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b8cdf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataReader(Dataset):\n",
    "    def __init__(self, dataset, transform=None):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x=self.dataset[index][0]\n",
    "        y=self.dataset[index][1]\n",
    "        if self.transform:\n",
    "            x=np.array(x)\n",
    "            x=self.transform(image=x)['image']\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "702ae946",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSmoothing(nn.Module):\n",
    "    \"\"\"NLL loss with label smoothing.\n",
    "    \"\"\"\n",
    "    def __init__(self, smoothing=0.0):\n",
    "        \"\"\"Constructor for the LabelSmoothing module.\n",
    "        :param smoothing: label smoothing factor\n",
    "        \"\"\"\n",
    "        super(LabelSmoothing, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "\n",
    "    def forward(self, x, target):\n",
    "        logprobs = torch.nn.functional.log_softmax(x, dim=-1)\n",
    "        nll_loss = -logprobs.gather(dim=-1, index=target.unsqueeze(1))\n",
    "        nll_loss = nll_loss.squeeze(1)\n",
    "        smooth_loss = -logprobs.mean(dim=-1)\n",
    "        loss = self.confidence * nll_loss + self.smoothing * smooth_loss\n",
    "        return loss.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18cd30da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurModel(LightningModule):\n",
    "    def __init__(self):\n",
    "        super(OurModel,self).__init__()\n",
    "        #architecute\n",
    "        self.model =  timm.create_model(model_name,pretrained=True)\n",
    "        self.fc1=nn.Linear(1000,500)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.fc2= nn.Linear(500,5)\n",
    " \n",
    "        #parameters\n",
    "        self.lr=1e-3\n",
    "        self.batch_size=128\n",
    "        self.numworker=12\n",
    "        self.acc = torchmetrics.Accuracy()\n",
    "        self.criterion=LabelSmoothing()\n",
    "        \n",
    "        self.trainacc,self.valacc=[],[]\n",
    "        self.trainloss,self.valloss=[],[]\n",
    "        \n",
    "        self.scheduler='constant'\n",
    "        \n",
    "        self.dataset=torchvision.datasets.ImageFolder('dataset')\n",
    "        \n",
    "        self.train_set, self.val_set =random_split(self.dataset, \n",
    "                            [int(len(self.dataset)*0.7), int(len(self.dataset)*0.3)])\n",
    "    def forward(self,x):\n",
    "        x= self.model(x)\n",
    "        x=self.fc1(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        opt=torch.optim.AdamW(params=self.parameters(),lr=self.lr )\n",
    "        if self.scheduler=='cosine':\n",
    "            scheduler=CosineAnnealingLR(opt,T_max=10,  eta_min=1e-6, last_epoch=-1)\n",
    "            return {'optimizer': opt,'lr_scheduler':scheduler}\n",
    "        elif self.scheduler=='reduce':\n",
    "            scheduler=ReduceLROnPlateau(opt,mode='min', factor=0.5, patience=5)\n",
    "            return {'optimizer': opt,'lr_scheduler':scheduler,'monitor':'val_loss'}\n",
    "        elif self.scheduler=='warm':\n",
    "            scheduler=CosineAnnealingWarmRestarts(opt,T_0=3, T_mult=1, eta_min=1e-6, last_epoch=-1)\n",
    "            return {'optimizer': opt,'lr_scheduler':scheduler}\n",
    "        elif self.scheduler=='constant':\n",
    "            return opt\n",
    " \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(DataReader(self.train_set,aug), batch_size = self.batch_size, \n",
    "                          num_workers=self.numworker,\n",
    "                          pin_memory=True,shuffle=False)\n",
    "\n",
    "    def training_step(self,batch,batch_idx):\n",
    "        image,label=batch\n",
    "        out = self(image)\n",
    "        loss=self.criterion(out,label)\n",
    "        acc=self.acc(out,label)\n",
    "        return {'loss':loss,'acc':acc}\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        loss=torch.stack([x[\"loss\"] for x in outputs]).mean().detach().cpu().numpy().round(2)\n",
    "        acc=torch.stack([x[\"acc\"] for x in outputs]).mean().detach().cpu().numpy().round(2)\n",
    "        self.trainacc.append(acc)\n",
    "        self.trainloss.append(loss)\n",
    "        #print('training loss accuracy ',self.current_epoch,loss, acc)\n",
    "        self.log('train_loss', loss)\n",
    "        self.log('train_acc', acc)\n",
    "        \n",
    "    def val_dataloader(self):\n",
    "        ds=DataLoader(DataReader(self.val_set,aug), batch_size = self.batch_size,\n",
    "                      num_workers=self.numworker,pin_memory=True, shuffle=False)\n",
    "        return ds\n",
    "\n",
    "    def validation_step(self,batch,batch_idx):\n",
    "        image,label=batch\n",
    "        out=self(image)\n",
    "        loss=self.criterion(out,label)\n",
    "        acc=self.acc(out,label)\n",
    "        return {'loss':loss,'acc':acc}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        loss=torch.stack([x[\"loss\"] for x in outputs]).mean().detach().cpu().numpy().round(2)\n",
    "        acc=torch.stack([x[\"acc\"] for x in outputs]).mean().detach().cpu().numpy().round(2)\n",
    "        self.valacc.append(acc)\n",
    "        self.valloss.append(loss)\n",
    "        print('validation loss accuracy ',self.current_epoch,loss, acc)\n",
    "        self.log('val_loss', loss)\n",
    "        self.log('val_acc', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4bdecfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='resnest50d'\n",
    "model=OurModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53f38d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "lr_monitor = LearningRateMonitor(logging_interval='epoch')\n",
    "trainer = Trainer(max_epochs=50, auto_lr_find=False, auto_scale_batch_size=False,\n",
    "                #deterministic=True,\n",
    "                gpus=-1,precision=16,\n",
    "                accumulate_grad_batches=1,\n",
    "                stochastic_weight_avg=False,\n",
    "                enable_progress_bar = False,\n",
    "                num_sanity_val_steps=0,\n",
    "                callbacks=[lr_monitor]\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b04bb53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "2021-12-06 23:27:59.523558: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | model     | ResNet         | 27.5 M\n",
      "1 | fc1       | Linear         | 500 K \n",
      "2 | relu      | ReLU           | 0     \n",
      "3 | fc2       | Linear         | 2.5 K \n",
      "4 | acc       | Accuracy       | 0     \n",
      "5 | criterion | LabelSmoothing | 0     \n",
      "---------------------------------------------\n",
      "28.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "28.0 M    Total params\n",
      "55.972    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss accuracy  0 1.11 0.52\n",
      "validation loss accuracy  1 1.19 0.5\n",
      "validation loss accuracy  2 1.06 0.56\n",
      "validation loss accuracy  3 0.87 0.63\n",
      "validation loss accuracy  4 0.93 0.6\n",
      "validation loss accuracy  5 0.99 0.6\n",
      "validation loss accuracy  6 0.89 0.62\n",
      "validation loss accuracy  7 1.79 0.58\n",
      "validation loss accuracy  8 0.9 0.63\n",
      "validation loss accuracy  9 0.84 0.65\n",
      "validation loss accuracy  10 0.8 0.66\n",
      "validation loss accuracy  11 0.76 0.69\n",
      "validation loss accuracy  12 0.75 0.69\n",
      "validation loss accuracy  13 0.8 0.67\n",
      "validation loss accuracy  14 0.77 0.69\n",
      "validation loss accuracy  15 0.75 0.69\n",
      "validation loss accuracy  16 1.79 0.46\n",
      "validation loss accuracy  17 0.77 0.68\n",
      "validation loss accuracy  18 0.79 0.68\n",
      "validation loss accuracy  19 0.73 0.7\n",
      "validation loss accuracy  20 0.72 0.7\n",
      "validation loss accuracy  21 0.82 0.66\n",
      "validation loss accuracy  22 0.74 0.7\n",
      "validation loss accuracy  23 0.76 0.69\n",
      "validation loss accuracy  24 0.72 0.71\n",
      "validation loss accuracy  25 0.86 0.66\n",
      "validation loss accuracy  26 0.75 0.7\n",
      "validation loss accuracy  27 0.77 0.7\n",
      "validation loss accuracy  28 0.76 0.69\n",
      "validation loss accuracy  29 0.75 0.69\n",
      "validation loss accuracy  30 0.76 0.7\n",
      "validation loss accuracy  31 0.75 0.7\n",
      "validation loss accuracy  32 0.72 0.71\n",
      "validation loss accuracy  33 0.78 0.69\n",
      "validation loss accuracy  34 0.74 0.7\n",
      "validation loss accuracy  35 1.12 0.61\n",
      "validation loss accuracy  36 1.75 0.61\n",
      "validation loss accuracy  37 1.06 0.52\n",
      "validation loss accuracy  38 0.87 0.62\n",
      "validation loss accuracy  39 0.79 0.66\n",
      "validation loss accuracy  40 0.9 0.65\n",
      "validation loss accuracy  41 0.79 0.67\n",
      "validation loss accuracy  42 0.77 0.69\n",
      "validation loss accuracy  43 0.75 0.7\n",
      "validation loss accuracy  44 0.85 0.66\n",
      "validation loss accuracy  45 0.79 0.69\n",
      "validation loss accuracy  46 0.75 0.7\n",
      "validation loss accuracy  47 0.82 0.67\n",
      "validation loss accuracy  48 0.81 0.68\n",
      "validation loss accuracy  49 0.76 0.69\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c906d9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss accuracy  49 0.75 0.7\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{'val_acc': 0.699999988079071, 'val_loss': 0.75}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 0.75, 'val_acc': 0.699999988079071}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.validate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0045ded9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=model.val_dataloader()\n",
    "model.cuda().eval()\n",
    "labels,preds=[],[]\n",
    "with torch.no_grad():\n",
    "    for batch in loader:\n",
    "        image,label=batch\n",
    "        pred=model(image.cuda())\n",
    "        pred=torch.argmax(pred,dim=1).detach().cpu().numpy()\n",
    "        labels.append(label.cpu().numpy())\n",
    "        preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3de410a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.91      0.80      1060\n",
      "           1       0.76      0.68      0.72       929\n",
      "           2       0.69      0.63      0.66       878\n",
      "           3       0.62      0.62      0.62       887\n",
      "           4       0.76      0.64      0.70       896\n",
      "\n",
      "    accuracy                           0.70      4650\n",
      "   macro avg       0.71      0.70      0.70      4650\n",
      "weighted avg       0.71      0.70      0.70      4650\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(np.hstack(labels),np.hstack(preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d832141",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
