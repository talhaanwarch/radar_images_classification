{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d02e6246",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pytorch_lightning import seed_everything, LightningModule, Trainer\n",
    "from sklearn.utils import class_weight\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from pytorch_lightning.callbacks import EarlyStopping,ModelCheckpoint,LearningRateMonitor\n",
    "from torch.optim.lr_scheduler import CyclicLR, ReduceLROnPlateau,CosineAnnealingWarmRestarts,OneCycleLR,CosineAnnealingLR\n",
    "import torchvision\n",
    "from sklearn.metrics import classification_report,f1_score,accuracy_score\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset,random_split\n",
    "import timm\n",
    "import torchmetrics\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fb17743",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size=224\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "aug= A.Compose([\n",
    "            A.Resize(img_size+32,img_size+32),\n",
    "            A.RandomCrop(img_size,img_size),\n",
    "            A.HorizontalFlip(0.5),\n",
    "            A.VerticalFlip(0.5),\n",
    "            A.ShiftScaleRotate(rotate_limit=3),\n",
    "            A.Blur(),A.RandomGamma(),\n",
    "            A.Sharpen(), A.GaussNoise(),\n",
    "            A.CoarseDropout(8,64,64),\n",
    "            A.CLAHE(0.5),\n",
    "            A.Normalize(),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "545e4b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataReader(Dataset):\n",
    "    def __init__(self, dataset, transform=None):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x=self.dataset[index][0]\n",
    "        y=self.dataset[index][1]\n",
    "        if self.transform:\n",
    "            x=np.array(x)\n",
    "            x=self.transform(image=x)['image']\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a15bd54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurModel(LightningModule):\n",
    "    def __init__(self):\n",
    "        super(OurModel,self).__init__()\n",
    "        #architecute\n",
    "        self.model =  timm.create_model(model_name,pretrained=True)\n",
    "        self.fc1=nn.Linear(1000,500)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.fc2= nn.Linear(500,5)\n",
    " \n",
    "        #parameters\n",
    "        self.lr=1e-3\n",
    "        self.batch_size=72\n",
    "        self.numworker=12\n",
    "        self.acc = torchmetrics.Accuracy()\n",
    "        self.criterion=nn.CrossEntropyLoss()\n",
    "        #LabelSmoothing()\n",
    "        \n",
    "        self.trainacc,self.valacc=[],[]\n",
    "        self.trainloss,self.valloss=[],[]\n",
    "        \n",
    "        self.scheduler='constant'\n",
    "        \n",
    "        self.dataset=torchvision.datasets.ImageFolder('dataset')\n",
    "        \n",
    "        self.train_set, self.val_set =random_split(self.dataset, \n",
    "                            [int(len(self.dataset)*0.8), int(len(self.dataset)*0.2)])\n",
    "    def forward(self,x):\n",
    "        x= self.model(x)\n",
    "        x=self.fc1(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        opt=torch.optim.AdamW(params=self.parameters(),lr=self.lr )\n",
    "        if self.scheduler=='cosine':\n",
    "            scheduler=CosineAnnealingLR(opt,T_max=10,  eta_min=1e-6, last_epoch=-1)\n",
    "            return {'optimizer': opt,'lr_scheduler':scheduler}\n",
    "        elif self.scheduler=='reduce':\n",
    "            scheduler=ReduceLROnPlateau(opt,mode='min', factor=0.5, patience=5)\n",
    "            return {'optimizer': opt,'lr_scheduler':scheduler,'monitor':'val_loss'}\n",
    "        elif self.scheduler=='warm':\n",
    "            scheduler=CosineAnnealingWarmRestarts(opt,T_0=10, T_mult=1, eta_min=1e-6, last_epoch=-1)\n",
    "            return {'optimizer': opt,'lr_scheduler':scheduler}\n",
    "        elif self.scheduler=='constant':\n",
    "            return opt\n",
    " \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(DataReader(self.train_set,aug), batch_size = self.batch_size, \n",
    "                          num_workers=self.numworker,\n",
    "                          pin_memory=True,shuffle=False)\n",
    "\n",
    "    def training_step(self,batch,batch_idx):\n",
    "        image,label=batch\n",
    "        out = self(image)\n",
    "        loss=self.criterion(out,label)\n",
    "        acc=self.acc(out,label)\n",
    "        return {'loss':loss,'acc':acc}\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        loss=torch.stack([x[\"loss\"] for x in outputs]).mean().detach().cpu().numpy().round(2)\n",
    "        acc=torch.stack([x[\"acc\"] for x in outputs]).mean().detach().cpu().numpy().round(2)\n",
    "        self.trainacc.append(acc)\n",
    "        self.trainloss.append(loss)\n",
    "        #print('training loss accuracy ',self.current_epoch,loss, acc)\n",
    "        self.log('train_loss', loss)\n",
    "        self.log('train_acc', acc)\n",
    "        \n",
    "    def val_dataloader(self):\n",
    "        ds=DataLoader(DataReader(self.val_set,aug), batch_size = self.batch_size,\n",
    "                      num_workers=self.numworker,pin_memory=True, shuffle=False)\n",
    "        return ds\n",
    "\n",
    "    def validation_step(self,batch,batch_idx):\n",
    "        image,label=batch\n",
    "        out=self(image)\n",
    "        loss=self.criterion(out,label)\n",
    "        acc=self.acc(out,label)\n",
    "        return {'loss':loss,'acc':acc}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        loss=torch.stack([x[\"loss\"] for x in outputs]).mean().detach().cpu().numpy().round(2)\n",
    "        acc=torch.stack([x[\"acc\"] for x in outputs]).mean().detach().cpu().numpy().round(2)\n",
    "        self.valacc.append(acc)\n",
    "        self.valloss.append(loss)\n",
    "        print('validation loss accuracy ',self.current_epoch,loss, acc)\n",
    "        self.log('val_loss', loss)\n",
    "        self.log('val_acc', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e8065c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='resnest50d'\n",
    "model=OurModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88d66c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "[W Context.cpp:69] Warning: torch.set_deterministic is in beta, and its design and  functionality may change in the future. (function operator())\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "lr_monitor = LearningRateMonitor(logging_interval='epoch')\n",
    "trainer = Trainer(max_epochs=50, auto_lr_find=False, auto_scale_batch_size=False,\n",
    "                deterministic=True,\n",
    "                gpus=-1,precision=16,\n",
    "                accumulate_grad_batches=4,\n",
    "                stochastic_weight_avg=False,\n",
    "                enable_progress_bar = False,\n",
    "                num_sanity_val_steps=0,\n",
    "                callbacks=[lr_monitor]\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c69b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "2021-12-06 16:08:30.354510: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | model     | ResNet           | 27.5 M\n",
      "1 | fc1       | Linear           | 500 K \n",
      "2 | relu      | ReLU             | 0     \n",
      "3 | fc2       | Linear           | 2.5 K \n",
      "4 | acc       | Accuracy         | 0     \n",
      "5 | criterion | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "28.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "28.0 M    Total params\n",
      "55.972    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss accuracy  0 1.97 0.3\n",
      "validation loss accuracy  1 1.42 0.4\n",
      "validation loss accuracy  2 1.25 0.45\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6341fffc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
