{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b3a418a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pytorch_lightning import seed_everything, LightningModule, Trainer\n",
    "from sklearn.utils import class_weight\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from pytorch_lightning.callbacks import EarlyStopping,ModelCheckpoint,LearningRateMonitor\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "import torchvision\n",
    "from sklearn.metrics import classification_report\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset,random_split\n",
    "import timm\n",
    "import torchmetrics\n",
    "import torchvision.models as models\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import pytorch_lightning as pl\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90c48dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version 1.7.1+cu110\n",
      "pytorch lightnging version 1.5.4\n",
      "sklearn version 1.0.1\n",
      "torchvision version 0.8.2+cu110\n",
      "albumentations version 1.1.0\n",
      "torchmetrics version 0.6.1\n"
     ]
    }
   ],
   "source": [
    "print('torch version',torch.__version__)\n",
    "print('pytorch lightnging version',pl.__version__)\n",
    "print('sklearn version',sklearn.__version__)\n",
    "print('torchvision version',torchvision.__version__)\n",
    "print('albumentations version',A.__version__)\n",
    "print('torchmetrics version',torchmetrics.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9202c770",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create data augmentation\n",
    "img_size=224\n",
    "aug= A.Compose([\n",
    "            A.Resize(img_size,img_size),\n",
    "            A.HorizontalFlip(0.5),\n",
    "            A.VerticalFlip(),\n",
    "            A.RandomRotate90(),\n",
    "            A.Normalize(),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef432f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a class to read data from folders and apply augmentation from albumentation\n",
    "class DataReader(Dataset):\n",
    "    def __init__(self, dataset, transform=None):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x=self.dataset[index][0]#read image\n",
    "        y=self.dataset[index][1] #read label\n",
    "        if self.transform:#apply augmentations\n",
    "            x=np.array(x)\n",
    "            x=self.transform(image=x)['image']\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12bdcaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurModel(LightningModule):\n",
    "    def __init__(self):\n",
    "        super(OurModel,self).__init__()\n",
    "        # model architecute\n",
    "        '''refernce:https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/efficientnet.py'''\n",
    "        self.model =  timm.create_model(model_name,pretrained=True)\n",
    "        self.fc1=nn.Linear(1000,500)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.fc2= nn.Linear(500,5)\n",
    " \n",
    "        #parameters\n",
    "        self.lr=1e-3\n",
    "        self.batch_size=64\n",
    "        self.numworker=12\n",
    "        self.acc = torchmetrics.Accuracy() #metric\n",
    "        self.criterion=nn.CrossEntropyLoss() #loss function\n",
    "        #list to store loss and accuracy\n",
    "        self.trainacc,self.valacc=[],[]\n",
    "        self.trainloss,self.valloss=[],[]\n",
    "        #load data        \n",
    "        self.dataset=torchvision.datasets.ImageFolder('dataset')\n",
    "        #split data\n",
    "        self.train_set, self.val_set =random_split(self.dataset,\n",
    "                            [int(len(self.dataset)*0.7), int(len(self.dataset)*0.3)],\n",
    "                                                  generator=torch.Generator().manual_seed(42))\n",
    "    def forward(self,x):\n",
    "        x= self.model(x)\n",
    "        x=self.fc1(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def mixup_data(self,x, y, alpha=1.0):\n",
    "        '''\n",
    "        Returns mixed inputs, pairs of targets, and lambda\n",
    "        reference: mixup: Beyond Empirical Risk Minimization\n",
    "        '''\n",
    "        if alpha > 0:\n",
    "            lam = np.random.beta(alpha, alpha)\n",
    "        else:\n",
    "            lam = 1\n",
    "\n",
    "        batch_size = x.size()[0]\n",
    "        index = torch.randperm(batch_size)\n",
    "        mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "        y_a, y_b = y, y[index]\n",
    "        return mixed_x, y_a, y_b, lam\n",
    "\n",
    "\n",
    "    def mixup_criterion(self, pred, y_a, y_b, lam):\n",
    "        return lam * self.criterion(pred, y_a) + (1 - lam) * self.criterion(pred, y_b)\n",
    "    \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        #optimizer and scheduler\n",
    "        opt=torch.optim.AdamW(params=self.parameters(),lr=self.lr )\n",
    "        scheduler=CosineAnnealingWarmRestarts(opt,T_0=10, T_mult=1, eta_min=1e-6, last_epoch=-1)\n",
    "        return {'optimizer': opt,'lr_scheduler':scheduler}\n",
    "\n",
    "    def train_dataloader(self):#load train \n",
    "        return DataLoader(DataReader(self.train_set,aug), batch_size = self.batch_size, \n",
    "                          num_workers=self.numworker,\n",
    "                          pin_memory=True,shuffle=True)\n",
    "\n",
    "    def training_step(self,batch,batch_idx):\n",
    "        image,label=batch\n",
    "        mixed_x, y_a, y_b, lam=self.mixup_data(image,label)#apply mixup\n",
    "        out = self(mixed_x)#pass images to model\n",
    "        loss=self.mixup_criterion(out,y_a, y_b, lam) #calculate loss\n",
    "        acc=self.acc(out,label)#calculate accuracy\n",
    "        return {'loss':loss,'acc':acc}\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        #average loss and accuracy in all batches of train data\n",
    "        loss=torch.stack([x[\"loss\"] for x in outputs]).mean().detach().cpu().numpy().round(2)\n",
    "        acc=torch.stack([x[\"acc\"] for x in outputs]).mean().detach().cpu().numpy().round(2)\n",
    "        self.trainacc.append(acc)\n",
    "        self.trainloss.append(loss)\n",
    "        self.log('train_loss', loss)\n",
    "        self.log('train_acc', acc)\n",
    "        \n",
    "    def val_dataloader(self):\n",
    "        ds=DataLoader(DataReader(self.val_set,aug), batch_size = self.batch_size,\n",
    "                      num_workers=self.numworker,pin_memory=True, shuffle=False)\n",
    "        return ds\n",
    "\n",
    "    def validation_step(self,batch,batch_idx):\n",
    "        image,label=batch\n",
    "        out=self(image)\n",
    "        loss=self.criterion(out,label)\n",
    "        acc=self.acc(out,label)\n",
    "        return {'loss':loss,'acc':acc}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        loss=torch.stack([x[\"loss\"] for x in outputs]).mean().detach().cpu().numpy().round(2)\n",
    "        acc=torch.stack([x[\"acc\"] for x in outputs]).mean().detach().cpu().numpy().round(2)\n",
    "        self.valacc.append(acc)\n",
    "        self.valloss.append(loss)\n",
    "        print('validation loss accuracy ',self.current_epoch,loss, acc)\n",
    "        self.log('val_loss', loss)\n",
    "        self.log('val_acc', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44d67b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='efficientnetv2_rw_s'\n",
    "model=OurModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "472f3d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "lr_monitor = LearningRateMonitor(logging_interval='epoch')\n",
    "checkpoint=ModelCheckpoint(dirpath='checkpoints',filename='file', monitor='val_acc', verbose=False, save_last=True, mode='max')\n",
    "trainer = Trainer(max_epochs=50, auto_lr_find=False, auto_scale_batch_size=False,\n",
    "                #deterministic=True,\n",
    "                gpus=-1,precision=16,\n",
    "                accumulate_grad_batches=1,\n",
    "                stochastic_weight_avg=False,\n",
    "                enable_progress_bar = False,\n",
    "                num_sanity_val_steps=0,\n",
    "                callbacks=[lr_monitor,checkpoint]\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "861ac403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('eff_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d69ed05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e8f25d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afc7034f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=model.val_dataloader()\n",
    "model.cuda().eval()\n",
    "labels,preds=[],[]\n",
    "with torch.no_grad():\n",
    "    for batch in loader:\n",
    "        image,label=batch\n",
    "        pred=model(image.cuda())\n",
    "        pred=torch.argmax(pred,dim=1).detach().cpu().numpy()\n",
    "        labels.append(label.cpu().numpy())\n",
    "        preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0c19139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.91      0.80      1011\n",
      "           1       0.72      0.75      0.73       885\n",
      "           2       0.71      0.68      0.70       894\n",
      "           3       0.75      0.63      0.68       951\n",
      "           4       0.78      0.70      0.74       909\n",
      "\n",
      "    accuracy                           0.74      4650\n",
      "   macro avg       0.74      0.73      0.73      4650\n",
      "weighted avg       0.74      0.74      0.73      4650\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(np.hstack(labels),np.hstack(preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d64659f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test time augmentation\n",
    "import ttach as tta\n",
    "transforms = tta.Compose(\n",
    "    [\n",
    "        tta.HorizontalFlip(),\n",
    "        tta.VerticalFlip(),\n",
    "        tta.Rotate90(angles=[0, 90,180,270]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "tta_model = tta.ClassificationTTAWrapper(model, transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "377d3cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=model.val_dataloader()\n",
    "model.cuda().eval()\n",
    "labels,preds=[],[]\n",
    "with torch.no_grad():\n",
    "    for batch in loader:\n",
    "        image,label=batch\n",
    "        pred=tta_model(image.cuda())\n",
    "        pred=torch.argmax(pred,dim=1).detach().cpu().numpy()\n",
    "        labels.append(label.cpu().numpy())\n",
    "        preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ad08050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.94      0.82      1011\n",
      "           1       0.74      0.76      0.75       885\n",
      "           2       0.75      0.69      0.72       894\n",
      "           3       0.77      0.65      0.70       951\n",
      "           4       0.81      0.71      0.76       909\n",
      "\n",
      "    accuracy                           0.75      4650\n",
      "   macro avg       0.76      0.75      0.75      4650\n",
      "weighted avg       0.76      0.75      0.75      4650\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(np.hstack(labels),np.hstack(preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae95222",
   "metadata": {},
   "source": [
    "# test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7e58118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '1', 1: '2', 2: '3', 3: '4', 4: '5'}\n"
     ]
    }
   ],
   "source": [
    "testset=torchvision.datasets.ImageFolder('test')\n",
    "testloader=DataLoader(DataReader(testset,aug), batch_size = model.batch_size,\n",
    "                      num_workers=model.numworker,pin_memory=True, shuffle=False)\n",
    "classes=model.dataset.class_to_idx\n",
    "classes={v:k for k,v in classes.items()}\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "882dcd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda().eval()\n",
    "labels,preds=[],[]#ignore labels\n",
    "with torch.no_grad():\n",
    "    for batch in testloader:\n",
    "        image,label=batch#ignore labels\n",
    "        pred=tta_model(image.cuda())\n",
    "        pred=torch.argmax(pred,dim=1).detach().cpu().numpy()\n",
    "        labels.append(label.cpu().numpy())#ignore labels\n",
    "        preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1fb19feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path=[i[0] for i in testset.imgs]\n",
    "predicted_label=[classes[i] for i in np.hstack(preds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bc0fca2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test/0/0a0ce6bd-8748-49ee-8129-30dae17e11e5.png': '2',\n",
       " 'test/0/0a6db652-8807-40c9-b074-22d184377800.png': '1'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(image_path,predicted_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ec84e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
